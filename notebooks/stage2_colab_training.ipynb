{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "097032f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    "  \"cells\": [\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"metadata\": {},\n",
    "      \"source\": [\n",
    "        \"# ðŸš€ Sarika AI - Stage 2 Training\\n\",\n",
    "        \"## Context Teachers Training on Colab T4 GPU\\n\",\n",
    "        \"\\n\",\n",
    "        \"**Total Time:** ~4-6 hours  \\n\",\n",
    "        \"**GPU:** T4 (16GB VRAM)\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"metadata\": {},\n",
    "      \"outputs\": [],\n",
    "      \"source\": [\n",
    "        \"# Check GPU\\n\",\n",
    "        \"!nvidia-smi\\n\",\n",
    "        \"\\n\",\n",
    "        \"import torch\\n\",\n",
    "        \"print(f\\\"\\\\nâœ“ PyTorch: {torch.__version__}\\\")\\n\",\n",
    "        \"print(f\\\"âœ“ CUDA: {torch.cuda.is_available()}\\\")\\n\",\n",
    "        \"if torch.cuda.is_available():\\n\",\n",
    "        \"    print(f\\\"âœ“ GPU: {torch.cuda.get_device_name(0)}\\\")\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"metadata\": {},\n",
    "      \"outputs\": [],\n",
    "      \"source\": [\n",
    "        \"# Mount Google Drive\\n\",\n",
    "        \"from google.colab import drive\\n\",\n",
    "        \"drive.mount('/content/drive')\\n\",\n",
    "        \"\\n\",\n",
    "        \"# Set working directory\\n\",\n",
    "        \"import os\\n\",\n",
    "        \"os.chdir('/content/drive/MyDrive')\\n\",\n",
    "        \"!mkdir -p sarika-ai\\n\",\n",
    "        \"%cd sarika-ai\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"metadata\": {},\n",
    "      \"outputs\": [],\n",
    "      \"source\": [\n",
    "        \"# Install dependencies\\n\",\n",
    "        \"!pip install -q transformers accelerate peft bitsandbytes datasets huggingface_hub\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"metadata\": {},\n",
    "      \"outputs\": [],\n",
    "      \"source\": [\n",
    "        \"# HuggingFace Login\\n\",\n",
    "        \"from huggingface_hub import login\\n\",\n",
    "        \"from getpass import getpass\\n\",\n",
    "        \"\\n\",\n",
    "        \"HF_TOKEN = getpass(\\\"Enter HF Token: \\\")\\n\",\n",
    "        \"login(token=HF_TOKEN)\\n\",\n",
    "        \"\\n\",\n",
    "        \"import os\\n\",\n",
    "        \"os.environ[\\\"HF_TOKEN\\\"] = HF_TOKEN\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"metadata\": {},\n",
    "      \"outputs\": [],\n",
    "      \"source\": [\n",
    "        \"# Create project structure\\n\",\n",
    "        \"!mkdir -p ml/core ml/training ml/checkpoints models/cache data\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"metadata\": {},\n",
    "      \"outputs\": [],\n",
    "      \"source\": [\n",
    "        \"%%writefile ml/config.py\\n\",\n",
    "        \"\\\"\\\"\\\"\\n\",\n",
    "        \"Sarika AI - Config (Colab)\\n\",\n",
    "        \"\\\"\\\"\\\"\\n\",\n",
    "        \"import torch\\n\",\n",
    "        \"from pathlib import Path\\n\",\n",
    "        \"import os\\n\",\n",
    "        \"\\n\",\n",
    "        \"# Paths\\n\",\n",
    "        \"PROJECT_ROOT = Path(\\\"/content/drive/MyDrive/sarika-ai\\\")\\n\",\n",
    "        \"CHECKPOINT_DIR = PROJECT_ROOT / \\\"ml\\\" / \\\"checkpoints\\\"\\n\",\n",
    "        \"MODEL_DIR = PROJECT_ROOT / \\\"models\\\"\\n\",\n",
    "        \"HF_HOME = str(PROJECT_ROOT / \\\"models\\\" / \\\"cache\\\")\\n\",\n",
    "        \"\\n\",\n",
    "        \"os.environ[\\\"HF_HOME\\\"] = HF_HOME\\n\",\n",
    "        \"os.environ[\\\"TRANSFORMERS_CACHE\\\"] = HF_HOME\\n\",\n",
    "        \"\\n\",\n",
    "        \"# Device\\n\",\n",
    "        \"DEVICE = \\\"cuda\\\" if torch.cuda.is_available() else \\\"cpu\\\"\\n\",\n",
    "        \"GPU_MEMORY_GB = 16\\n\",\n",
    "        \"HF_TOKEN = os.getenv(\\\"HF_TOKEN\\\")\\n\",\n",
    "        \"\\n\",\n",
    "        \"class TrainingConfig:\\n\",\n",
    "        \"    LORA_R = 16\\n\",\n",
    "        \"    LORA_ALPHA = 32\\n\",\n",
    "        \"    LORA_DROPOUT = 0.05\\n\",\n",
    "        \"    LORA_TARGET_MODULES = [\\\"q_proj\\\", \\\"k_proj\\\", \\\"v_proj\\\", \\\"o_proj\\\", \\\"gate_proj\\\", \\\"up_proj\\\", \\\"down_proj\\\"]\\n\",\n",
    "        \"    LEARNING_RATE = 2e-4\\n\",\n",
    "        \"    WEIGHT_DECAY = 0.01\\n\",\n",
    "        \"    MAX_GRAD_NORM = 1.0\\n\",\n",
    "        \"    MAX_SEQ_LENGTH = 512\\n\",\n",
    "        \"    BATCH_SIZE = 1\\n\",\n",
    "        \"    DISTILLATION_ALPHA = 0.5\\n\",\n",
    "        \"    TEMPERATURE = 2.0\\n\",\n",
    "        \"\\n\",\n",
    "        \"class LogConfig:\\n\",\n",
    "        \"    LOG_STEPS = 10\\n\",\n",
    "        \"    SAVE_STEPS = 100\\n\",\n",
    "        \"\\n\",\n",
    "        \"class SpaceConfig:\\n\",\n",
    "        \"    MAX_TOTAL_USAGE = 50\\n\",\n",
    "        \"    CLEANUP_THRESHOLD = 80\\n\",\n",
    "        \"    MAX_CHECKPOINTS = 3\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"metadata\": {},\n",
    "      \"outputs\": [],\n",
    "      \"source\": [\n",
    "        \"# Upload your base_trainer.py and stage2_context_teachers.py here\\n\",\n",
    "        \"# Or use file upload widget\\n\",\n",
    "        \"from google.colab import files\\n\",\n",
    "        \"\\n\",\n",
    "        \"print(\\\"Upload these files:\\\")\\n\",\n",
    "        \"print(\\\"1. ml/core/base_trainer.py\\\")\\n\",\n",
    "        \"print(\\\"2. ml/training/stage2_context_teachers.py\\\")\\n\",\n",
    "        \"\\n\",\n",
    "        \"# uploaded = files.upload()\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"metadata\": {},\n",
    "      \"outputs\": [],\n",
    "      \"source\": [\n",
    "        \"# Alternative: Clone from GitHub (if you push code there)\\n\",\n",
    "        \"# !git clone https://github.com/yourusername/sarika-ai.git\\n\",\n",
    "        \"# %cd sarika-ai\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"metadata\": {},\n",
    "      \"source\": [\n",
    "        \"## ðŸš€ Start Training\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"metadata\": {},\n",
    "      \"outputs\": [],\n",
    "      \"source\": [\n",
    "        \"# Run training\\n\",\n",
    "        \"!python ml/training/stage2_context_teachers.py\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"metadata\": {},\n",
    "      \"outputs\": [],\n",
    "      \"source\": [\n",
    "        \"# Monitor GPU\\n\",\n",
    "        \"!watch -n 5 nvidia-smi\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"metadata\": {},\n",
    "      \"outputs\": [],\n",
    "      \"source\": [\n",
    "        \"# Check checkpoints\\n\",\n",
    "        \"!ls -lh ml/checkpoints/stage2_context_teachers/\"\n",
    "      ]\n",
    "    }\n",
    "  ],\n",
    "  \"metadata\": {\n",
    "    \"accelerator\": \"GPU\",\n",
    "    \"colab\": {\n",
    "      \"gpuType\": \"T4\",\n",
    "      \"provenance\": []\n",
    "    },\n",
    "    \"kernelspec\": {\n",
    "      \"display_name\": \"Python 3\",\n",
    "      \"name\": \"python3\"\n",
    "    }\n",
    "  },\n",
    "  \"nbformat\": 4,\n",
    "  \"nbformat_minor\": 0\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6457724",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "uploaded = files.upload()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
