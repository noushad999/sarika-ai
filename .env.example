# ============================================
# SARIKA AI - Environment Configuration
# Copy to .env and fill in your values
# ============================================

# ============================================
# HARDWARE & SYSTEM
# ============================================
DEVICE=cuda                      # cuda, cpu, mps (Mac)
MIXED_PRECISION=fp16             # fp16, bf16, fp32
GPU_MEMORY_GB=16                 # Your GPU VRAM
SSD_SPACE_GB=200                 # Available SSD space
MAX_WORKERS=8                    # CPU cores for data loading

# ============================================
# HUGGING FACE
# ============================================
HF_TOKEN=your_huggingface_token_here
  # Get from https://huggingface.co/settings/tokens
HF_HOME=./models/cache                # Cache directory
HF_HUB_OFFLINE=false                  # Set true for offline mode

# ============================================
# MODEL CONFIGURATION
# ============================================

# Stage 1: Giant Teachers (Cloud - Colab)
GIANT_LLAMA=meta-llama/Llama-3.1-70B-Instruct
GIANT_QWEN=Qwen/Qwen2.5-72B-Instruct
GIANT_MISTRAL=mistralai/Mistral-Large-Instruct-2411
GIANT_GEMMA=google/gemma-2-27b-it
GIANT_PHI=microsoft/Phi-3.5-MoE-instruct

# Stage 2: Intermediate Teacher
INTERMEDIATE_MODEL=meta-llama/Llama-3.1-8B-Instruct

# Stage 3: Context Teachers (7B-9B)
CONTEXT_BENGALI=mistralai/Mistral-7B-Instruct-v0.3
CONTEXT_EMOTION=Qwen/Qwen2.5-7B-Instruct
CONTEXT_CONVERSATION=meta-llama/Llama-3.1-8B-Instruct
CONTEXT_HUMOR=google/gemma-2-9b-it
CONTEXT_DEEP=mistralai/Mistral-7B-Instruct-v0.3
CONTEXT_CRISIS=Qwen/Qwen2.5-7B-Instruct

# Stage 4: Integration Teacher
INTEGRATION_MODEL=meta-llama/Llama-3.1-8B-Instruct

# Stage 5: Domain Specialists (3B)
SPECIALIST_MODEL=meta-llama/Llama-3.2-3B-Instruct

# Final: Student Model (1B)
STUDENT_MODEL=meta-llama/Llama-3.2-1B-Instruct

# ============================================
# TRAINING HYPERPARAMETERS
# ============================================
BATCH_SIZE=2                     # Per device batch size
GRADIENT_ACCUMULATION=8          # Effective batch = 2 * 8 = 16
LEARNING_RATE=2e-4               # Learning rate
NUM_EPOCHS=3                     # Training epochs
MAX_SEQ_LENGTH=512               # Maximum sequence length
WARMUP_STEPS=100                 # Warmup steps
WEIGHT_DECAY=0.01                # Weight decay
MAX_GRAD_NORM=1.0                # Gradient clipping

# LoRA Configuration
LORA_R=16                        # LoRA rank
LORA_ALPHA=32                    # LoRA alpha
LORA_DROPOUT=0.05                # LoRA dropout
LORA_TARGET_MODULES=q_proj,v_proj,k_proj,o_proj

# Distillation
DISTILLATION_ALPHA=0.5           # KL div weight (0.5 = equal KL + CE)
TEMPERATURE=2.0                  # Softmax temperature

# ============================================
# SPACE MANAGEMENT
# ============================================
AUTO_CLEANUP=true                # Auto delete old checkpoints
MAX_CHECKPOINTS=2                # Keep last N checkpoints
CLEANUP_THRESHOLD=85             # Cleanup when disk > 85%

# ============================================
# PATHS
# ============================================
DATA_DIR=./data
MODEL_DIR=./models
CHECKPOINT_DIR=./ml/checkpoints
LOG_DIR=./logs
OUTPUT_DIR=./outputs

# ============================================
# LOGGING & MONITORING
# ============================================
LOG_LEVEL=INFO                   # DEBUG, INFO, WARNING, ERROR
WANDB_PROJECT=sarika-ai          # Weights & Biases project
WANDB_ENABLED=false              # Set true to enable W&B
TENSORBOARD_ENABLED=true         # TensorBoard logging

# ============================================
# DATASET
# ============================================
DATASET_NAME=custom_bengali      # Dataset name
TRAIN_SPLIT=train                # Training split
VAL_SPLIT=validation             # Validation split
TEST_SPLIT=test                  # Test split
NUM_WORKERS=4                    # Data loader workers

# ============================================
# BACKEND API (For Later)
# ============================================
API_HOST=0.0.0.0
API_PORT=8000
DATABASE_URL=postgresql://user:pass@localhost:5432/sarika
REDIS_URL=redis://localhost:6379/0
SECRET_KEY=your-secret-key-change-this
CORS_ORIGINS=http://localhost:3000,http://localhost:8000

# ============================================
# CLOUD SETUP (Stage 1)
# ============================================
COLAB_NOTEBOOK_URL=https://colab.research.google.com/drive/1JKH1aTUmuQWd_uSjEsfTa5tJeyVISw67
GOOGLE_DRIVE_FOLDER_ID=1W58oFDtxV1AJzBPls-fVnjHJS3SMsUhG  # For saving outputs
COLAB_GPU=T4                 # T4, V100, A100
